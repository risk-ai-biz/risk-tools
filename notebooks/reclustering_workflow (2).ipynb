{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a511e676",
   "metadata": {},
   "source": [
    "# Counterparty **Re‑clustering** Analytics Workbook\n",
    "This interactive notebook walks through a **rolling‑window clustering** workflow for equities‑trading counterparties.  We focus on three analytic questions:\n",
    "1. **Are we using the *right* number of clusters (`k`) at any point in time?**  \n",
    "   → Inspect internal quality metrics such as *silhouette*, *Davies‑Bouldin*.\n",
    "2. **How does the *importance of features* evolve over time?**  \n",
    "   → Train a lightweight **XGBoost** classifier window‑by‑window and track `gain` feature importances.\n",
    "3. **Which clusters are *emerging* (growing fast) or *volatile* (frequent member churn)?**  \n",
    "   → Compare cluster summaries across adjacent windows.\n",
    "\n",
    "We rely on the `constrained_clustering` utility module created earlier ‑‑ it gives us size‑balanced K‑Means, volume‑share repair, rolling‑window helpers, and ready‑made Seaborn FacetGrid plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a7a4b",
   "metadata": {},
   "source": [
    "## 0. Environment & dependencies\n",
    "**Purpose:** ensure required libraries are present.\n",
    "\n",
    "Run the `pip install` line only the *first* time you open the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e8c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install polars scikit-learn xgboost seaborn tqdm matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc01678",
   "metadata": {},
   "source": [
    "## 1. Imports, plotting theme, and data load\n",
    "**Purpose:** set a clean plotting theme via **Seaborn** and bring the trade history into memory with the helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06ffaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import constrained_clustering as cc\n",
    "\n",
    "sns.set_theme(style='whitegrid', context='notebook')\n",
    "\n",
    "TRADE_GLOB = Path('/data/equities/trades_*.parquet')  # adjust to your location\n",
    "trades = cc.load_trade_history(str(TRADE_GLOB))\n",
    "print(f'Trades loaded: {trades.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0043acc3",
   "metadata": {},
   "source": [
    "## 2. Define rolling time windows\n",
    "**Methodology:** 90‑day overlapping windows stepped every 30 days.  This captures *local* behaviour while giving enough samples per window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_DAYS = 90\n",
    "STEP_DAYS = 30\n",
    "windows = cc.generate_time_windows(trades, window_days=WINDOW_DAYS, step_days=STEP_DAYS)\n",
    "print(f'{len(windows)} windows spanning {windows[0][0].date()} – {windows[-1][1].date()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9205e6fd",
   "metadata": {},
   "source": [
    "## 3. Choosing the number of clusters, *k*\n",
    "**Purpose:** use *silhouette* to compare clustering quality across a range of `k` values.\n",
    "\n",
    "**What to look for:**\n",
    "* Higher median silhouette is better.\n",
    "* Watch for a *knee* where gains flatten — often indicates the sweet‑spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6f1367",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = range(4, 13)  # evaluate k = 4–12\n",
    "silhouette_by_k = {k: [] for k in k_range}\n",
    "\n",
    "for start, end in tqdm(windows, desc='Windows'):\n",
    "    win_trades = trades.filter((pl.col('ts') >= start) & (pl.col('ts') < end))\n",
    "    if win_trades.is_empty():\n",
    "        continue\n",
    "    X, agg, _ = cc.build_counterparty_features(win_trades)\n",
    "    for k in k_range:\n",
    "        labels, _ = cc.cluster_counterparties(X, n_clusters=k, size_min=5)\n",
    "        sil = cc.evaluate_clustering(X, labels)['silhouette']\n",
    "        silhouette_by_k[k].append(sil)\n",
    "\n",
    "sil_df = pd.DataFrame(silhouette_by_k)\n",
    "sil_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e151449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Seaborn boxplot of silhouette scores ---\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "sns.boxplot(data=sil_df, ax=ax)\n",
    "ax.set_xlabel('k (number of clusters)')\n",
    "ax.set_ylabel('Silhouette')\n",
    "ax.set_title('Silhouette distribution across windows')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7925053",
   "metadata": {},
   "source": [
    "### Decision: pick the `k` with the highest *average* silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa74535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_SELECTED = int(sil_df.mean().idxmax())\n",
    "print(f'Chosen k = {K_SELECTED}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21df9684",
   "metadata": {},
   "source": [
    "## 4. Run full rolling pipeline with the chosen `k`\n",
    "**Purpose:** produce a time‑series of clustering results, aligned across windows, plus internal metrics for each window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cc.cluster_over_time(trades, windows,\n",
    "                               n_clusters=K_SELECTED,\n",
    "                               size_min=5,\n",
    "                               max_share=0.20)  # no client >20 % notional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a061a2",
   "metadata": {},
   "source": [
    "## 5. Cluster stability over time\n",
    "**Methodology:** use *Adjusted Rand index* (ARI) between adjacent windows.\n",
    "\n",
    "**Interpretation tips:**\n",
    "* ARI near **1.0** → clusters are stable.\n",
    "* Dips signal structural shifts in counterparty behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45222774",
   "metadata": {},
   "outputs": [],
   "source": [
    "stability = cc.evaluate_stability_over_time(results)\n",
    "stability.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c744ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "sns.lineplot(data=stability, x='window_end', y='adjusted_rand', marker='o', ax=ax)\n",
    "ax.set_title('Adjusted Rand index (cluster stability)')\n",
    "ax.set_xlabel('Window end date')\n",
    "ax.set_ylabel('ARI')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83555120",
   "metadata": {},
   "source": [
    "## 6. Feature‑importance drift using XGBoost\n",
    "**Methodology:** train a simple **XGBoost** multi‑class classifier in each window, then record `gain` feature importances.\n",
    "\n",
    "**What to watch:** which drivers of cluster membership are trending up/down?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d8467c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "feat_cols = ['avg_pnl', 'std_pnl', 'tot_ntl', 'trade_count', 'avg_participation']\n",
    "fi_over_time = {c: [] for c in feat_cols}\n",
    "\n",
    "for res in tqdm(results, desc='Windows (XGB)'):\n",
    "    X = res.agg.select(feat_cols).to_numpy()\n",
    "    y = res.labels\n",
    "    model = xgb.XGBClassifier(max_depth=3, n_estimators=120, learning_rate=0.1, verbosity=0)\n",
    "    model.fit(X, y)\n",
    "    for c, imp in zip(feat_cols, model.feature_importances_):\n",
    "        fi_over_time[c].append(imp)\n",
    "\n",
    "fi_df = pd.DataFrame(fi_over_time)\n",
    "fi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0521af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Seaborn area plot for top features ---\n",
    "top_feats = fi_df.mean().sort_values(ascending=False).head(4).index\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "fi_df[top_feats].plot(kind='area', stacked=True, ax=ax, alpha=0.8)\n",
    "ax.set_xlabel('Window index')\n",
    "ax.set_ylabel('Gain importance')\n",
    "ax.set_title('Feature importance drift (top 4)')\n",
    "ax.legend(loc='upper right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b89dde1",
   "metadata": {},
   "source": [
    "## 7. Intra‑cluster feature distributions (latest window)\n",
    "**Purpose:** inspect how features are distributed *within* each cluster.\n",
    "\n",
    "**Tool:** leverage `cc.plot_feature_distributions` which internally builds a Seaborn **FacetGrid**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1eca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = results[-1]\n",
    "fig = cc.plot_feature_distributions(latest.agg, latest.labels, kind='hist', bins=40, col_wrap=3)\n",
    "fig.suptitle('Feature distributions by cluster – latest window', y=1.02)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433d15ce",
   "metadata": {},
   "source": [
    "## 8. Emerging clusters\n",
    "**Methodology:** flag clusters whose number of counterparties grows by >50 % relative to the previous window.\n",
    "\n",
    "**Actionable insight:** these clusters might deserve bespoke spread rules or deeper investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90dc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "emerging = []\n",
    "for prev, curr in zip(results[:-1], results[1:]):\n",
    "    prev_ct = prev.summary.sort('cluster_notional')\n",
    "    curr_ct = curr.summary.sort('cluster_notional')\n",
    "    merged = prev_ct.join(curr_ct, on='cluster', how='inner', suffix='_curr')\n",
    "    growth = (\n",
    "        (merged['n_counterparties_curr'] - merged['n_counterparties']) / merged['n_counterparties']\n",
    "    )\n",
    "    big = merged.filter(growth > 0.5)\n",
    "    for row in big.iter_rows():\n",
    "        emerging.append({'window_end': curr.end.date(), 'cluster': row['cluster'], 'growth_pct': growth[big.row_indices[0]]})\n",
    "\n",
    "pd.DataFrame(emerging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79db7585",
   "metadata": {},
   "source": [
    "---\n",
    "### Wrap‑up\n",
    "* Re‑run the silhouette section regularly — cluster structure can drift.\n",
    "* Use feature‑importance drift to update the feature pipeline (e.g. add/remove metrics).\n",
    "* Automate the entire workflow on a schedule and push the key plots to your reporting dashboard.\n",
    "\n",
    "Happy clustering!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
